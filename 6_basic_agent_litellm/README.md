# üê± Neko Restaurant Agent with LiteLLM + OpenAI

**Neko Restaurant Agent** ‡∏Ñ‡∏∑‡∏≠ AI Agent ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ [Google Agent Development Kit (ADK)](https://github.com/google-deepmind/agent-development-kit) ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö [LiteLLM](https://docs.litellm.ai/) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô **OpenAI GPT models** ‡πÅ‡∏ó‡∏ô Gemini

Agent ‡∏ô‡∏µ‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£, ‡πÄ‡∏ä‡πá‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≠‡∏á‡πÇ‡∏ï‡πä‡∏∞‡πÑ‡∏î‡πâ, ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏•‡∏á‡πÉ‡∏ô‡∏ï‡∏∞‡∏Å‡∏£‡πâ‡∏≤  
Agent ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ **"‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~"**

---

## ‚ú® Features

### Core Features
- **‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£**: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏°‡∏ô‡∏π‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô "‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô", "‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠", "‡∏ã‡∏π‡∏ä‡∏¥"
- **‡πÄ‡∏ä‡πá‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏à‡∏≠‡∏á‡πÇ‡∏ï‡πä‡∏∞**: ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≠‡∏á‡πÇ‡∏ï‡πä‡∏∞‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
- **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏•‡∏á‡∏ï‡∏∞‡∏Å‡∏£‡πâ‡∏≤**: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏∞‡∏Å‡∏£‡πâ‡∏≤‡∏™‡∏±‡πà‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
- **‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö**: ‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢ "‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß~"

### LiteLLM + OpenAI Features
- **ADK Agent (Completion API)**: ‡πÉ‡∏ä‡πâ `google.adk.models.lite_llm.LiteLlm` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö OpenAI models
- **GPT-5 Parameters**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö `reasoning_effort` ‡πÅ‡∏•‡∏∞ `verbosity` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPT-5 models
- **Responses API (Direct)**: ‡πÉ‡∏ä‡πâ `litellm.responses()` ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Reusable Prompts

---

## üì¶ Requirements
- Python 3.10+
- ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Google ADK ‡πÅ‡∏•‡∏∞ LiteLLM
```bash
pip install google-adk litellm python-dotenv
```

---

## üîß Environment Variables

‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô `.env` file:
```bash
# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL_ID=gpt-5-mini-2025-08-07  # or gpt-5.1-2025-11-13, gpt-4.1-2025-04-14
```

---

## ‚öôÔ∏è LiteLlm Configuration Parameters

`LiteLlm` accepts `**kwargs` which are passed to `litellm.acompletion()`.

### Standard Parameters (All Models)

| Parameter | Type | Description |
|-----------|------|-------------|
| `temperature` | float | Sampling temperature (0-2). **Note**: GPT-5 series uses fixed 1.0 |
| `max_tokens` | int | Maximum tokens in response |
| `max_completion_tokens` | int | Upper bound for completion tokens |
| `top_p` | float | Nucleus sampling parameter |
| `presence_penalty` | float | Penalize based on token presence (-2.0 to 2.0) |
| `frequency_penalty` | float | Penalize based on token frequency (-2.0 to 2.0) |
| `stop` | str/list | Stop sequences |
| `seed` | int | Random seed for reproducibility |
| `logit_bias` | dict | Modify token probabilities |
| `user` | str | User identifier for tracking |
| `response_format` | dict | Response format specification |
| `logprobs` | bool | Return log probabilities |
| `top_logprobs` | int | Number of top logprobs to return |
| `extra_headers` | dict | Additional HTTP headers |
| `api_base` | str | Custom API base URL |
| `api_key` | str | API key override |

### GPT-5 / Reasoning Model Parameters

| Parameter | Type | Values | Description |
|-----------|------|--------|-------------|
| `reasoning_effort` | str | `"none"`, `"minimal"`, `"low"`, `"medium"`, `"high"`, `"default"` | Controls reasoning depth for o1, o3, gpt-5 series |
| `verbosity` | str | `"low"`, `"medium"`, `"high"` | Controls response length for GPT-5 models |

### Example Configuration

```python
from google.adk.models.lite_llm import LiteLlm

# Basic configuration
model = LiteLlm(
    model="openai/gpt-4o",
    temperature=0.7,
    max_tokens=1000,
)

# GPT-5 with reasoning and verbosity
model = LiteLlm(
    model="openai/gpt-5-mini-2025-08-07",
    max_tokens=1000,
    reasoning_effort="low",   # Controls reasoning depth
    verbosity="medium",       # Controls response length
)
```

---

## üöÄ Usage

### Run with ADK Web UI (Completion API)
```bash
adk web 6_basic_agent_litellm
```

### Run Responses API Demo (Verbosity + Reusable Prompts)
```bash
python 6_basic_agent_litellm/agent.py
```

---

## üìñ Code Examples

### 1. ADK Agent with LiteLLM + GPT-5
```python
from google.adk.agents import Agent
from google.adk.models.lite_llm import LiteLlm

# Create model with GPT-5 parameters
model = LiteLlm(
    model="openai/gpt-5-mini-2025-08-07",
    max_tokens=1000,
    reasoning_effort="low",
    verbosity="medium",
)

agent = Agent(
    name="my_agent",
    model=model,
    description="My agent powered by GPT-5",
    instruction="You are a helpful assistant.",
    tools=[my_tool],
)
```

### 2. Reusable Prompts (via Responses API)
```python
from litellm import responses as litellm_responses

# Use a stored prompt template from OpenAI
response = litellm_responses(
    model="openai/gpt-5-mini-2025-08-07",
    prompt={
        "id": "pmpt_abc123",  # Your stored prompt ID
        "variables": {
            "customer_name": "John",
            "product": "Ramen"
        }
    },
    text={"verbosity": "medium"}
)
```

---

## üìä Feature Support

| Feature | GPT-4 Series | GPT-5 Series |
|---------|--------------|--------------|
| `temperature` | ‚úÖ Configurable | ‚ùå Fixed at 1.0 |
| `max_tokens` | ‚úÖ | ‚úÖ |
| `reasoning_effort` | ‚ùå | ‚úÖ |
| `verbosity` | ‚ùå | ‚úÖ |
| Tool calling | ‚úÖ | ‚úÖ |
| Streaming | ‚úÖ | ‚úÖ |

---

## üìö References
- [LiteLLM + Google ADK Tutorial](https://docs.litellm.ai/docs/tutorials/google_adk)
- [OpenAI Responses API](https://docs.litellm.ai/docs/providers/openai/responses_api)
- [Google ADK Documentation](https://github.com/google-deepmind/agent-development-kit)