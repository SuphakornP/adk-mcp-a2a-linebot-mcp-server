#!/usr/bin/env python3
"""
Ingest Data to Pinecone Index with Integrated Embedding
- ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å sample_data/
- ‡πÅ‡∏ö‡πà‡∏á chunk
- Upsert ‡πÄ‡∏Ç‡πâ‡∏≤ Pinecone (Pinecone ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å OpenAI API ‡πÄ‡∏≠‡∏á!
"""

import os
import json
from pathlib import Path
from typing import List, Dict
from dotenv import load_dotenv
from pinecone import Pinecone

# Load environment variables
load_dotenv()

# Configuration
INDEX_NAME = "test-rag-integrated"
NAMESPACE = ""  # Empty string for default namespace (not "__default__")
CHUNK_SIZE = 500  # ‡∏Ç‡∏ô‡∏≤‡∏î chunk (characters)
CHUNK_OVERLAP = 50  # overlap ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunk

def load_sample_data() -> List[Dict[str, str]]:
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• sample ‡∏à‡∏≤‡∏Å sample_data/"""
    sample_data_dir = Path(__file__).parent / "sample_data"
    
    if not sample_data_dir.exists():
        print(f"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {sample_data_dir}")
        print("üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• sample ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á...")
        sample_data_dir.mkdir(exist_ok=True)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• sample
        sample_docs = [
            {
                "title": "‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç",
                "content": """
                ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà:
                
                1. ‡∏Å‡∏≤‡∏£‡∏ü‡∏±‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à (Active Listening) - ‡∏ô‡∏±‡∏Å‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏ü‡∏±‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏à 
                ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏û‡∏π‡∏î‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∂‡∏Å‡∏ã‡∏∂‡πâ‡∏á
                
                2. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ß‡πâ‡∏ß‡∏≤‡∏á‡πÉ‡∏à (Building Trust) - ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ß‡∏Å‡πÄ‡∏Ç‡∏≤‡πÑ‡∏ß‡πâ‡∏ß‡∏≤‡∏á‡πÉ‡∏à 
                ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ß‡πâ‡∏ß‡∏≤‡∏á‡πÉ‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏≤‡∏®‡∏±‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏ï‡∏¢‡πå ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏ô‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
                
                3. ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå (Product Knowledge) - ‡∏ô‡∏±‡∏Å‡∏Ç‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏ï‡∏ô‡πÄ‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∂‡∏Å‡∏ã‡∏∂‡πâ‡∏á 
                ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ
                """,
                "category": "sales_skills"
            },
            {
                "title": "‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢",
                "content": """
                ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:
                
                1. ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡πÅ‡∏ö‡∏ö‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô (Assumptive Close) - ‡∏ó‡∏≥‡πÄ‡∏™‡∏°‡∏∑‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô 
                ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡πà‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö?" ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ "‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?"
                
                2. ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡πÅ‡∏ö‡∏ö‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (Alternative Close) - ‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 
                ‡πÄ‡∏ä‡πà‡∏ô "‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏∏‡πà‡∏ô A ‡∏´‡∏£‡∏∑‡∏≠ B ‡∏Ñ‡∏£‡∏±‡∏ö?" ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà "‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ã‡∏∑‡πâ‡∏≠‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?"
                
                3. ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô (Urgency Close) - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô 
                ‡πÄ‡∏ä‡πà‡∏ô "‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏û‡∏µ‡∏¢‡∏á 3 ‡∏ß‡∏±‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô" ‡∏´‡∏£‡∏∑‡∏≠ "‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏≠‡∏µ‡∏Å‡πÅ‡∏Ñ‡πà 2 ‡∏ä‡∏¥‡πâ‡∏ô"
                
                4. ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡πÅ‡∏ö‡∏ö‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (Risk Reversal Close) - ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 
                ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô 30 ‡∏ß‡∏±‡∏ô‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ü‡∏£‡∏µ 14 ‡∏ß‡∏±‡∏ô"
                """,
                "category": "sales_techniques"
            },
            {
                "title": "‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤",
                "content": """
                ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û:
                
                1. ‡∏ü‡∏±‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡πà‡∏≠‡∏ô - ‡∏≠‡∏¢‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÇ‡∏ï‡πâ‡πÅ‡∏¢‡πâ‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏ô‡∏à‡∏ö
                
                2. ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏à - ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ç‡∏≤ 
                ‡πÄ‡∏ä‡πà‡∏ô "‡∏ú‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏£‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤"
                
                3. ‡∏ä‡∏µ‡πâ‡πÅ‡∏à‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - ‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Å‡∏±‡∏á‡∏ß‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô
                
                4. ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠ - ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Å‡∏±‡∏á‡∏ß‡∏•‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ 
                "‡∏Ñ‡∏∏‡∏ì‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏™‡∏ö‡∏≤‡∏¢‡πÉ‡∏à‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?" ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏ï‡πà‡∏≠
                
                ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢:
                - "‡πÅ‡∏û‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ" ‚Üí ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πà‡∏≤‡πÅ‡∏•‡∏∞ ROI
                - "‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡∏Å‡πà‡∏≠‡∏ô" ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á
                - "‡∏°‡∏µ‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß" ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö
                """,
                "category": "objection_handling"
            }
        ]
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å sample data
        for i, doc in enumerate(sample_docs):
            file_path = sample_data_dir / f"sample_{i+1}.json"
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(doc, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• sample {len(sample_docs)} ‡πÑ‡∏ü‡∏•‡πå")
        
        # Return ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (Best Practice)
        return sample_docs
    
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
    documents = []
    for file_path in sample_data_dir.glob("*.json"):
        with open(file_path, 'r', encoding='utf-8') as f:
            documents.append(json.load(f))
    
    print(f"üìÇ ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå: {len(documents)} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    return documents

def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:
    """‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô chunks ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢"""
    chunks = []
    start = 0
    text_length = len(text)
    
    while start < text_length:
        end = start + chunk_size
        chunk = text[start:end]
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà chunk ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        if end < text_length:
            last_space = chunk.rfind(' ')
            if last_space != -1:
                chunk = chunk[:last_space]
                end = start + last_space
        
        chunks.append(chunk.strip())
        start = end - overlap  # overlap ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤ context
    
    return [c for c in chunks if c]  # ‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á

def ingest_documents():
    """Main ingestion function with Integrated Embedding"""
    print("=" * 80)
    print("üì¶ Data Ingestion Process (Integrated Embedding)")
    print("=" * 80)
    
    # Initialize Pinecone client
    print("\n‚öôÔ∏è  ‡∏Å‡∏≥‡∏•‡∏±‡∏á initialize Pinecone client...")
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    index = pc.Index(INDEX_NAME)
    
    # Load documents
    print("\nüìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    documents = load_sample_data()
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(documents)} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    
    # Check if we have documents
    if not documents:
        print("\n‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞ ingest!")
        print("üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå JSON ‡πÉ‡∏ô sample_data/ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")
        return
    
    # Process and upsert
    print("\nüîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á process ‡πÅ‡∏•‡∏∞ upsert ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    print("üí° Pinecone ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥!\n")
    
    all_records = []
    
    for doc_idx, doc in enumerate(documents):
        print(f"üìÑ Processing: {doc['title']}")
        
        # Chunk the content
        chunks = chunk_text(doc['content'])
        print(f"   - Chunks: {len(chunks)}")
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° records ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö upsert_records
        # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡πÄ‡∏≠‡∏á!
        for chunk_idx, chunk in enumerate(chunks):
            record_id = f"doc_{doc_idx}_chunk_{chunk_idx}"
            
            # Record format ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö integrated embedding
            # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ field "content" ‡∏ï‡∏≤‡∏° field_map ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ
            record = {
                "_id": record_id,
                "content": chunk,  # field ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å embed ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                "title": doc["title"],
                "category": doc["category"],
                "chunk_index": chunk_idx,
                "total_chunks": len(chunks)
            }
            
            all_records.append(record)
        
        print(f"   ‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° {len(chunks)} records")
    
    # Check if we have records to upsert
    if not all_records:
        print("\n‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ records ‡∏ó‡∏µ‡πà‡∏à‡∏∞ upsert!")
        print("üí° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ content ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")
        return
    
    # Upsert to Pinecone using upsert_records (for integrated embedding)
    print(f"\n‚¨ÜÔ∏è  ‡∏Å‡∏≥‡∏•‡∏±‡∏á upsert {len(all_records)} records ‡πÄ‡∏Ç‡πâ‡∏≤ Pinecone...")
    print("‚ö° Pinecone ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥...\n")
    
    # Upsert in batches
    # Note: namespace ‡πÄ‡∏õ‡πá‡∏ô parameter ‡πÅ‡∏£‡∏Å (positional), records ‡πÄ‡∏õ‡πá‡∏ô parameter ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á
    # Best Practice: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö integrated embedding ‡πÉ‡∏ä‡πâ batch_size = 96 (‡∏ï‡∏≤‡∏° Pinecone docs)
    batch_size = 96
    for i in range(0, len(all_records), batch_size):
        batch = all_records[i:i+batch_size]
        try:
            index.upsert_records(NAMESPACE, batch)
            print(f"   - Upserted batch {i//batch_size + 1} ({len(batch)} records)")
        except Exception as e:
            print(f"   ‚ùå Error upserting batch {i//batch_size + 1}: {str(e)}")
            raise
    
    print("\n‚úÖ Upsert ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    print("üéâ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å embed ‡πÅ‡∏•‡∏∞ index ‡πÇ‡∏î‡∏¢ Pinecone ‡πÅ‡∏•‡πâ‡∏ß!")
    
    # Show index stats
    print("\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ Index:")
    stats = index.describe_index_stats()
    print(f"   - Total vectors: {stats.total_vector_count:,}")
    print(f"   - Dimension: {stats.dimension}")
    if stats.namespaces:
        for ns, info in stats.namespaces.items():
            ns_name = ns if ns else "(default)"
            print(f"   - Namespace '{ns_name}': {info.vector_count:,} vectors")

def main():
    """Main function"""
    try:
        ingest_documents()
        
        print("\n" + "=" * 80)
        print("‚úÖ Data ingestion completed successfully!")
        print("=" * 80)
        print("\nüìñ Next step:")
        print("   ‡∏£‡∏±‡∏ô: python agent.py ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö RAG chat")
        
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
